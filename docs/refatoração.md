[02/01, 15:38] Mr. Rian: üöÄ Croqui de Arquitetura: Atenbot MVP (Gemini Edition)

Objetivo: Bot de WhatsApp que processa Texto e √Åudio (entrada) e responde via Texto (sa√≠da) usando IA.
1. Stack Tecnol√≥gica Recomendada

    Linguagem: Python 3.10+

    Framework API: FastAPI (ass√≠ncrono e leve).

    IA (LLM & STT): Google Gemini 1.5 Flash (API via google-generativeai).

    Integra√ß√£o WhatsApp: Evolution API (via Docker) ou Z-API.

    Banco de Dados: SQLite (para o hist√≥rico de chat).

    Servidor: Docker / Docker Compose.

2. Fluxo da Mensagem (Diagrama de Sequ√™ncia)

    Usu√°rio envia √°udio/texto no WhatsApp.

    WhatsApp Gateway dispara um Webhook (POST) para o nosso Backend.

    Backend recebe o JSON:

        Se texto: Envia direto para o Gemini.

        Se √°udio: Baixa o arquivo .ogg, envia para o Gemini (Multimodal) ou transcreve via Whisper.

    Gemini processa o hist√≥rico + nova mensagem e gera o texto de resposta.

    Backend salva a troca no banco e faz um POST de volta para o Gateway enviando a resposta ao usu√°rio.
[02/01, 15:38] Mr. Rian: Estrutura de Pastas (Projeto)

atenbot/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # Entrypoint FastAPI e Rotas de Webhook
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini_ai.py # Integra√ß√£o com a API do Google
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ whatsapp.py  # Fun√ß√µes de envio de mensagem
‚îÇ   ‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py    # Schema do SQLite (id, user_id, message, role)
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ audio.py     # Convers√£o de √°udio se necess√°rio
‚îú‚îÄ‚îÄ .env                 # Chaves de API (GEMINI_API_KEY, WHATSAPP_TOKEN)
‚îú‚îÄ‚îÄ docker-compose.yml   # Orquestra√ß√£o do Backend + Evolution API
‚îî‚îÄ‚îÄ requirements.txt     # Depend√™ncias (fastapi, google-generativeai, sqlalchemy)
[02/01, 15:39] Mr. Rian: O Cora√ß√£o do C√≥digo (Pseudo-c√≥digo para o Dev)

O desenvolvedor deve implementar a classe de IA seguindo este padr√£o:

import google.generativeai as genai

class AtenbotAI:
    def __init__(self, api_key):
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')

    def get_response(self, user_id, message_content, is_audio=False):
        # 1. Recuperar hist√≥rico do SQLite para o user_id
        history = db.get_recent_messages(user_id)
        
        # 2. Configurar o "System Instruction"
        chat = self.model.start_chat(history=history)
        
        # 3. Gerar resposta
        response = chat.send_message(message_content)
        
        # 4. Salvar nova itera√ß√£o no banco
        db.save_message(user_id, message_content, response.text)
        
        return response.text
[02/01, 15:39] Mr. Rian: 5. Requisitos para o Desenvolvedor (Definition of Done)

    Baixa Lat√™ncia: O bot deve responder em menos de 5 segundos.

    Tratamento de √Åudio: O sistema deve detectar que a mensagem √© um arquivo, baixar e transcrever antes de enviar ao Gemini.

    Resili√™ncia: Se a API do Gemini falhar, o bot deve enviar uma mensagem de "Estou pensando, um momento".

    Contexto: O bot deve lembrar o nome do usu√°rio se ele o disser na primeira mensagem.
[02/01, 15:40] Mr. Rian: Docker Compose (A Infraestrutura Completa)

Este arquivo deve ser colocado na raiz do projeto. Ele sobe o Atenbot e a Evolution API (que conecta ao WhatsApp).
[02/01, 15:40] Mr. Rian: version: '3.8'

services:
  # O C√©rebro do Atenbot (Python/FastAPI)
  atenbot-app:
    build: .
    container_name: atenbot-backend
    restart: always
    env_file: .env
    ports:
      - "8000:8000"
    depends_on:
      - atenbot-db

  # Banco de Dados para Mem√≥ria de Longo Prazo
  atenbot-db:
    image: postgres:15
    container_name: atenbot-db
    restart: always
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: password123
      POSTGRES_DB: atenbot_memory
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # Gateway para WhatsApp (Evolution API)
  evolution-api:
    image: atendimentos/evolution-api:latest
    container_name: evolution-api
    restart: always
    ports:
      - "8080:8080"
    environment:
      - SERVER_URL=http://localhost:8080
      - DOCKER_NAME=evolution-api
    volumes:
      - evolution_instances:/evolution/instances

volumes:
  postgres_data:
  evolution_instances:
[02/01, 15:41] Mr. Rian: Esquema do Banco de Dados (A Mem√≥ria)

Passe isto ao desenvolvedor para que ele crie as tabelas. Usaremos uma estrutura que permite o "Omnichannel" (WhatsApp + Instagram no futuro).
[02/01, 15:41] Mr. Rian: -- Tabela de Usu√°rios (Unifica WhatsApp e Instagram)
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    wa_number VARCHAR(20) UNIQUE, -- N√∫mero do WhatsApp
    ig_handle VARCHAR(50) UNIQUE, -- @ do Instagram (futuro)
    name VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Tabela de Hist√≥rico de Mensagens (Contexto para o Gemini)
CREATE TABLE chat_messages (
    id SERIAL PRIMARY KEY,
    user_id UUID REFERENCES users(id),
    role VARCHAR(10), -- 'user' ou 'assistant'
    content TEXT,     -- A mensagem de texto ou transcri√ß√£o
    media_url TEXT,   -- Link se for √°udio/imagem
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
[02/01, 15:41] Mr. Rian: Checklist de Entrega para o Desenvolvedor

Para que ele n√£o erre na implementa√ß√£o, entregue estes 3 pontos:

    Conex√£o Gemini: Utilizar o m√©todo history= da biblioteca do Google para que o Gemini j√° receba as √∫ltimas 10 mensagens do banco automaticamente.

    Convers√£o de √Åudio: O √°udio do WhatsApp vem em .ogg. Ele deve usar a biblioteca pydub ou ffmpeg para garantir que o Gemini processe o som corretamente (ou enviar direto se usar a API multimodal).

    Seguran√ßa: As chaves de API do Gemini e do WhatsApp nunca devem estar no c√≥digo, apenas no arquivo .env.
[02/01, 16:05] Mr. Rian: Detalhamento T√©cnico: Rota /webhook

O desenvolvedor deve configurar esta rota no FastAPI (Python) para escutar as notifica√ß√µes da Evolution API.
1. O Fluxo L√≥gico da Rota

A rota n√£o pode apenas "processar". Ela deve seguir este fluxo de decis√£o:

    Valida√ß√£o: Verifica se a mensagem cont√©m texto ou m√≠dia (√°udio).

    Extra√ß√£o: Captura o n√∫mero do usu√°rio (remoteJid) e o conte√∫do.

    Normaliza√ß√£o de √Åudio: Se for √°udio, a rota faz o download do .ogg e o envia para a API do Gemini (que aceita arquivos bin√°rios) ou o transcreve.

    Chamada √† IA: Envia o conte√∫do + hist√≥rico do banco para o Gemini 1.5 Flash.

    Resposta: Faz o "callback" enviando a mensagem final para o WhatsApp do usu√°rio.
[02/01, 16:05] Mr. Rian: from fastapi import APIRouter, Request, BackgroundTasks
import httpx

router = APIRouter()

@router.post("/webhook/whatsapp")
async def handle_whatsapp(request: Request, background_tasks: BackgroundTasks):
    data = await request.json()
    
    # 1. Filtro: Ignora se for mensagem enviada pelo pr√≥prio bot
    if data.get("event") != "messages.upsert" or data['data']['key']['fromMe']:
        return {"status": "ignored"}

    # 2. Extra√ß√£o de dados b√°sicos
    user_number = data['data']['key']['remoteJid']
    message_type = "text" if 'conversation' in data['data']['message'] else "audio"
    
    # 3. Processamento em Segundo Plano (Background Task)
    # Isso evita que o WhatsApp d√™ timeout esperando a IA responder
    background_tasks.add_task(process_atenbot_logic, user_number, data['data']['message'], message_type)

    return {"status": "received"}

async def process_atenbot_logic(user_id, message_data, m_type):
    # Aqui o Dev chama o Gemini e depois a fun√ß√£o de envio
    content = ""
    if m_type == "audio":
        # L√≥gica para baixar o √°udio e converter/transcrever
        pass
    else:
        content = message_data['conversation']
        
    response_text = await gemini_service.generate(user_id, content)
    await whatsapp_service.send_text(user_id, response_text)
[02/01, 16:05] Mr. Rian: . Especifica√ß√µes para o Desenvolvedor

    Endpoint: POST /webhook/whatsapp

    Seguran√ßa: Implementar um X-API-KEY no cabe√ßalho para garantir que apenas a sua inst√¢ncia da Evolution API consiga enviar dados para essa rota.

    Tratamento de Erros: Se o Gemini demorar mais de 10 segundos, o c√≥digo deve disparar uma resposta autom√°tica: "Estou processando seu √°udio, s√≥ um instante..." para manter a fluidez da conversa.
[02/01, 16:05] Mr. Rian: Configura√ß√£o do Webhook no Gateway

O desenvolvedor precisar√° configurar a URL de destino na Evolution API da seguinte forma:

    URL: https://seu-servidor.com/webhook/whatsapp

    Eventos: Marcar apenas MESSAGES_UPSERT.


    Resumo Executivo
‚ÄãO Atenbot √© um Bot de WhatsApp Ass√≠ncrono projetado para velocidade. Ele desacopla o recebimento da mensagem do processamento da IA usando uma fila em mem√≥ria (Redis).
‚ÄãFilosofia: "Fire-and-Forget" (Recebe e libera a conex√£o imediatamente).
‚ÄãEstrat√©gia de √Åudio: Processamento em mem√≥ria via Base64 (Zero Disk I/O) para m√°xima performance em nuvem.
‚Äã1. Arquitetura do Sistema
‚ÄãO Fluxo de Dados:
‚ÄãWhatsApp recebe mensagem ‚Üí Evolution API envia Webhook.
‚ÄãAPI Gateway (Fastify) recebe JSON ‚Üí Joga na Fila (Redis) ‚Üí Responde 200 OK (Lat√™ncia < 50ms).
‚ÄãWorker (Node.js) pega o job ‚Üí Envia Texto/√Åudio (Base64) para Gemini.
‚ÄãGemini gera resposta ‚Üí Worker envia para Evolution API.
‚Äã2. Stack Tecnol√≥gica ("The Golden Stack")
‚ÄãRuntime: Node.js 20 (Alpine Linux).
‚ÄãWeb Framework: Fastify (Alta performance).
‚ÄãQueue Manager: BullMQ + Redis (Gest√£o de fila robusta).
‚ÄãIA Engine: Google Gemini 1.5 Flash (R√°pido, barato e multimodal).
‚ÄãIntegra√ß√£o: Evolution API v2 (Configurada para enviar Base64).
‚ÄãDeploy: Docker Compose (Port√°vel para qualquer Cloud).
‚Äã3. Implementa√ß√£o Pr√°tica (C√≥digos-Chave)
‚ÄãA. Configura√ß√£o do Webhook (Fastify + BullMQ)
‚ÄãArquivo: src/server.js
Objetivo: Receber a requisi√ß√£o e liberar o WhatsApp instantaneamente.


import Fastify from 'fastify';
import { Queue } from 'bullmq';

const app = Fastify({ logger: true });
const msgQueue = new Queue('atenbot-queue', { connection: { host: 'redis', port: 6379 } });

app.post('/webhook', async (req, reply) => {
  const { event, data } = req.body;

  // 1. Filtro de Seguran√ßa
  if (event !== 'messages.upsert' || data.key.fromMe) {
    return { status: 'ignored' };
  }

  // 2. Extra√ß√£o R√°pida (Payload Leve)
  const payload = {
    remoteJid: data.key.remoteJid,
    pushName: data.pushName,
    message: data.message,
    isAudio: !!data.message.audioMessage
  };

  // 3. Enfileirar (Fire-and-Forget)
  await msgQueue.add('chat-job', payload, {
    removeOnComplete: true, // Limpa o Redis automaticamente
    attempts: 2 // Retenta se falhar
  });

  return { status: 'queued' };
});

app.listen({ port: 3000, host: '0.0.0.0' });

B. O Worker Inteligente (Processamento IA)
‚ÄãArquivo: src/worker.js
Objetivo: Processar a l√≥gica pesada em segundo plano.

import { Worker } from 'bullmq';
import { GoogleGenerativeAI } from '@google/generative-ai';
import axios from 'axios';

// Configura√ß√£o Gemini
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });

// System Prompt (A Personalidade)
const SYSTEM_INSTRUCTION = `
Voc√™ √© o Atenbot. Responda de forma natural, curta e amig√°vel no WhatsApp.
Se receber √°udio, mencione brevemente que ouviu. Use emojis moderadamente.
Nunca use listas longas ou formata√ß√£o markdown complexa (negrito use *texto*).
`;

const worker = new Worker('atenbot-queue', async (job) => {
  const { remoteJid, pushName, message, isAudio } = job.data;
  
  try {
    // 1. Enviar "Digitando..." (Melhora UX)
    await sendPresence(remoteJid, 'composing');

    let promptParts = [SYSTEM_INSTRUCTION];
    
    // 2. Tratamento de √Åudio (Estrat√©gia Base64)
    if (isAudio) {
        // A Evolution deve estar configurada para enviar o base64 no JSON
        // ou fazemos uma chamada r√°pida para pegar o base64 se vier apenas URL
        const base64Audio = message.audioMessage.base64; 
        promptParts.push({
            inlineData: {
                data: base64Audio,
                mimeType: "audio/ogg"
            }
        });
        promptParts.push(`O usu√°rio ${pushName} enviou este √°udio. Responda.`);
    } else {
        const text = message.conversation || message.extendedTextMessage?.text;
        promptParts.push(`Usu√°rio ${pushName} diz: ${text}`);
    }

    // 3. Gerar Resposta
    const result = await model.generateContent(promptParts);
    const responseText = result.response.text();

    // 4. Enviar Resposta
    await sendMessage(remoteJid, responseText);

  } catch (err) {
    console.error("Erro no Worker:", err);
  }
}, { connection: { host: 'redis', port: 6379 } });

// Fun√ß√µes auxiliares (axios) para chamar Evolution API omitidas para brevidade

4. Configura√ß√£o da Evolution API (Crucial)
‚ÄãPara que a estrat√©gia de Base64 funcione (evitando download de arquivo), configure a Evolution API com estas vari√°veis de ambiente no docker-compose.yml:


environment:
  - WEBSOCKET_ENABLED=false
  # For√ßa a Evolution a incluir o base64 do √°udio no webhook
  - WEBHOOK_BASE64=true 
  - WEBSOCKET_EVENTS=MESSAGES_UPSERT

5. Infraestrutura Final (Docker Compose)
‚ÄãArquivo √∫nico para rodar tudo (docker-compose.yml):
version: '3.8'

services:
  atenbot-app:
    build: .
    restart: always
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - EVOLUTION_URL=http://evolution-api:8080
      - EVOLUTION_API_KEY=${EVOLUTION_API_KEY}
    depends_on:
      - redis
      - evolution-api

  redis:
    image: redis:alpine
    command: redis-server --save "" --appendonly no # Otimizado para performance (sem persist√™ncia disco)

  evolution-api:
    image: atendimentos/evolution-api:v2.1.1
    ports:
      - "8080:8080"
    environment:
      - SERVER_URL=http://evolution-api:8080
      - DOCKER_NAME=evolution-api
      - WEBHOOK_GLOBAL_URL=http://atenbot-app:3000/webhook
      - WEBHOOK_EVENTS=MESSAGES_UPSERT
      - WEBHOOK_BASE64=true # O Segredo da velocidade
    volumes:
      - evolution_instances:/evolution/instances

volumes:
  evolution_instances:
Onde buscar os dados? (A Mem√≥ria)
‚ÄãO Gemini n√£o "lembra" da mensagem anterior por conta pr√≥pria. N√≥s precisamos enviar o hist√≥rico da conversa a cada nova intera√ß√£o.
‚ÄãPara isso, adicionaremos um container PostgreSQL ao seu Docker Compose e usaremos o Prisma ORM no Node.js (padr√£o de mercado pela facilidade e tipagem).
‚ÄãEstrat√©gia de "Inje√ß√£o de Contexto"
‚ÄãNo Worker (src/worker.js), antes de chamar o Gemini, faremos o seguinte:
‚ÄãBuscar User: Verifica se o n√∫mero (remoteJid) j√° existe. Se n√£o, cria.
‚ÄãResgatar Hist√≥rico: Busca as √∫ltimas 20 mensagens dessa conversa.
‚ÄãMontar o Payload: Envia para o Gemini: [System Prompt] + [Hist√≥rico] + [Nova Mensagem].
‚ÄãO Schema do Banco (Prisma)
‚ÄãEntregue isso ao desenvolvedor (schema.prisma):

import { db } from '../services/prisma.js'; // Cliente do Banco
import { model } from '../services/gemini.js';

// ... (dentro da fun√ß√£o do worker)

// 1. Identificar ou Criar Usu√°rio no Banco
let user = await db.user.findUnique({ where: { whatsapp: remoteJid } });
if (!user) {
    user = await db.user.create({ 
        data: { whatsapp: remoteJid, name: pushName } 
    });
}

// 2. Resgatar Hist√≥rico (Contexto)
const history = await db.message.findMany({
    where: { userId: user.id },
    orderBy: { createdAt: 'desc' },
    take: 10 // Pega as √∫ltimas 10 trocas para dar contexto
});

// Converter para formato do Gemini e inverter para ordem cronol√≥gica
const chatHistory = history.reverse().map(msg => ({
    role: msg.role,
    parts: [{ text: msg.content }]
}));

// 3. Inicializar o Chat com a Personalidade
const chat = model.startChat({
    history: chatHistory,
    systemInstruction: {
        role: "system",
        parts: [{ text: "Cole aqui o Manifesto do Atenbot definido acima..." }]
    }
});

// 4. Enviar a Nova Mensagem
const result = await chat.sendMessage(inputContent);
const responseText = result.response.text();

// 5. Salvar a nova intera√ß√£o no Banco (Persist√™ncia)
await db.message.createMany({
    data: [
        { content: inputContent, role: 'user', userId: user.id },
        { content: responseText, role: 'model', userId: user.id }
    ]
});



4. O "Pulo do Gato" para Dados Reais do Cliente
‚ÄãVoc√™ perguntou onde ele busca os dados do cliente (ex: "Qual status do meu pedido?"). O Gemini por si s√≥ n√£o sabe disso.
‚ÄãPara o MVP ficar profissional, o arquiteto recomenda o uso de Function Calling (Ferramentas) do Gemini.
‚ÄãSe voc√™ tiver uma API (ou mesmo uma planilha simulada) com dados de clientes, n√≥s ensinamos o bot a consultar l√°:
‚ÄãO usu√°rio pergunta: "Meu boleto vence quando?"
‚ÄãO Gemini analisa e pensa: "Preciso consultar a ferramenta consultar_boleto".
‚ÄãO seu c√≥digo Node.js executa a fun√ß√£o, busca no banco, e devolve o JSON pro Gemini.
‚ÄãO Gemini responde: "Jo√£o, seu boleto vence dia 15/10. Quer que eu envie o PDF?"
‚ÄãResumo da Solu√ß√£o:
‚ÄãConsist√™ncia de Voz: Resolvida via System Instruction fixo.
‚ÄãContexto da Conversa: Resolvido via PostgreSQL injetando as √∫ltimas 10 mensagens.
‚ÄãDados do Neg√≥cio: (Futuro) Resolvido via Function Calling conectando ao seu ERP/CRM.


